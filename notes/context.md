hey guys, just wanted to drop some info from some of my conversations with max via facetime for context:

I think our facefusion is probably like 90% optimized, so this last mile is more incremental, but at our scale it can have a huge effect, and being best in class is very important
the experts on facefusion are the devs (henry is the main dev and there are a few people who are really helpful). they respond in their discord. they're very particular. you have to ask good questions, and they make sure you do the work first. i have a side account i use to ask questions there, and i recommend doing the same.
the main eval of this is the eye test. i think having a sample of ~10 different videos (short ~5-10s clips) that dont swap well for various reason is a good sample. then you should have two columns, one for the current implementation of face swap (can use our website to make sure it's the latest prod release) vs. your candidate. if your candidate fixes the majority of the issues, to the maximal extent possible, that's great, and once you reach a point where you dont think you can push it any further, great, let's ship this thing. if you need me to, i can try to find more examples in prod of videos with issues. testing on montage videos, like videos with multiple faces and quick cuts, is also one helpful approach, because there's likely at least one issue in it.
we do care about speed because it often trades off with quality. however, users care about quality first, and often when we figure out quality, we can solve for speed more easily, and there are often smart ways to make the tradeoff hurt less, like using conditional logic on running more compute intensive code
lastly, there are likely creative solutions outside the realm of facefusion, so i wouldnt limit yourself to that repo. other models can sometimes help, like max testing using a model to determine face alignment.