{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this pipeline needs to be able to detect if a person is horizontal and if so is the persons head facing to the left or right vertically\n",
    "\n",
    "based on that observation we can make the decision which value we should choose for detecting the face\n",
    "\n",
    "1. input the image and then return in prompt if horizontal and if so if left or right facing\n",
    "\n",
    "2. extract result from prompt \n",
    "\n",
    "3. based on result return the value 0 or 90 or 270\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install litellm python-dotenv opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from litellm import completion\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment_of_faces(vision_frame) -> str:\n",
    "\t#!only temporarly for testing in prod the vision frame will be no path\n",
    "\tvision_frame = cv2.imread(vision_frame)\n",
    "\n",
    "\t# Convert frame to PNG in memory and encode to base64\n",
    "\t_, buffer = cv2.imencode('.png', vision_frame)\n",
    "\tbase64_image = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "\t# Make API call to vision model\n",
    "\tresponse = completion(\n",
    "\t\tmodel=\"gpt-4o-mini\",\n",
    "\t\tmessages=[\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\t\"text\": \"You are getting an image as input. You need to say if the person in the image is horizontally or vertically aligned, and you also need to say if the person in the image is more left or right facing. It's also possible that it may not be possible to detect, or there is no person in the image. Keep your response short.\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\t\t\"image_url\": {\n",
    "\t\t\t\t\t\t\t\"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t]\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t)\n",
    "\treturn response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "value=get_alignment_of_faces(\"horizontal-example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the result from the response\n",
    "def extract_result(response: str) -> str:\n",
    "\t\"\"\"\n",
    "\tthis function should extract horizontal left - 90 or right - 270 or nothing - 0\n",
    "\t\"\"\"\n",
    "\tprompt = f\"\"\"\n",
    "\tYou are getting a response from an image detection as input - your task is to extract the detection result. If the detection result is horizontal left, you need to return 90; if it is right, return 270. In all other cases, when the response is unclear or doesn't make sense, return 0. Here is the response:\n",
    "\n",
    "\t{response}\n",
    "\n",
    "\tYour output needs to be in JSON format and only contain the value 90, 270 or 0 nothing else!\n",
    "\t\"\"\"\n",
    "\tresponse = completion(\n",
    "    \tmodel = \"gpt-4o\", \n",
    "\t\tresponse_format={ \"type\": \"json_object\" },\n",
    "    \tmessages=[{ \"content\": prompt,\"role\": \"user\"}],\n",
    "\t\ttemperature=0.0\n",
    "\t)\n",
    "\tresponse_json = json.loads(response.choices[0].message.content)\n",
    "\t#how to make sure that the model really only responds with one value ie 90 or 270 or 0?\n",
    "\treturn response_json[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=extract_result(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
